{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764cac1a-c3d3-49b8-8bbd-188fca177860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "拉取总进度：500/4412，已跳过 500/4412"
     ]
    }
   ],
   "source": [
    "import tushare as ts\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import time\n",
    "from sqlalchemy import text\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import concurrent.futures\n",
    "\n",
    "# 读取包含股票代码的 CSV 文件\n",
    "stock_list = pd.read_csv('./基础数据_预处理20241123.csv')\n",
    "stock_codes = stock_list['ts_code'].values\n",
    "\n",
    "# 设置 Tushare Token\n",
    "token = '6488998e7e15b3596e11308b921fdc726d3401cd4bde7958d3ba49cd'\n",
    "pro = ts.pro_api(token)\n",
    "\n",
    "# 使用 SQLAlchemy 和 pymysql 创建 MySQL 数据库连接\n",
    "engine = create_engine('mysql+pymysql://root@localhost:3306/stocks_data')\n",
    "\n",
    "# 插入数据到 MySQL 的函数\n",
    "def insert_sql(data, db_name, if_exists='append'):\n",
    "    try:\n",
    "        data.to_sql(db_name, engine, index=False, if_exists=if_exists)\n",
    "        return True  # 插入成功时返回 True\n",
    "    except Exception as e:\n",
    "        return False  # 插入失败时返回 False\n",
    "\n",
    "# 记录成功与失败的股票信息\n",
    "def log_status(ts_code, status, error_message=''):\n",
    "    status_data = {\n",
    "        'ts_code': ts_code,\n",
    "        'status': status,  # 'success' 或 'failure'\n",
    "        'error_message': error_message\n",
    "    }\n",
    "    status_df = pd.DataFrame([status_data])\n",
    "    status_df.to_sql('stock_data_status', engine, index=False, if_exists='append')\n",
    "\n",
    "# 查询数据库中某个股票的最新交易日期\n",
    "def get_last_trade_date(ts_code):\n",
    "    query = text(f\"SELECT MAX(trade_date) FROM stock_data WHERE ts_code='{ts_code}'\")\n",
    "    with engine.connect() as connection:\n",
    "        result = connection.execute(query).fetchone()\n",
    "    return result[0] if result else None\n",
    "\n",
    "# 拉取股票数据并插入\n",
    "def fetch_and_insert_single_stock(code, start_date, end_date, retries=3):\n",
    "    # 查询数据库中该股票已有的最新日期\n",
    "    last_date = get_last_trade_date(code)\n",
    "    \n",
    "    if last_date:\n",
    "        # 如果数据库已有数据，从最后一条记录的日期+1天开始拉取\n",
    "        start_date = str(int(last_date) + 1)\n",
    "    else:\n",
    "        # 如果数据库中没有该股票的数据，从2015年开始拉取\n",
    "        start_date = '20150101'\n",
    "\n",
    "    attempt = 0\n",
    "    success = False\n",
    "    while attempt < retries and not success:\n",
    "        try:\n",
    "            # 拉取股票的日线数据\n",
    "            data = pro.daily(ts_code=code, start_date=start_date, end_date=end_date)\n",
    "            \n",
    "            if data is not None and len(data) > 0:  # 判断是否有数据返回\n",
    "                # 将数据插入数据库\n",
    "                if insert_sql(data, 'stock_data'):\n",
    "                    log_status(code, 'success')  # 成功插入日志\n",
    "                    return (code, 'success', None)\n",
    "                else:\n",
    "                    log_status(code, 'failure', '插入数据库失败')\n",
    "                    attempt += 1\n",
    "            else:\n",
    "                log_status(code, 'failure', '无数据返回')\n",
    "                return (code, 'failure', '无数据返回')\n",
    "        except Exception as e:\n",
    "            log_status(code, 'failure', str(e))\n",
    "            attempt += 1\n",
    "\n",
    "    return (code, 'failure', '超过最大重试次数')\n",
    "\n",
    "\n",
    "# 拉取股票数据并插入（并行化版本）\n",
    "def fetch_and_insert_data_parallel(stock_codes, start_date, end_date, retries=3):\n",
    "    total_stocks = len(stock_codes)  # 获取总股票数量\n",
    "    skipped_count = 0  # 跳过的股票数量\n",
    "    new_count = 0  # 成功上传的新股票数量\n",
    "\n",
    "    # 使用线程池来并行处理股票代码\n",
    "    def process_stock(code):\n",
    "        nonlocal skipped_count, new_count\n",
    "        last_date = get_last_trade_date(code)\n",
    "\n",
    "        if last_date:\n",
    "            start_date = str(int(last_date) + 1)\n",
    "        else:\n",
    "            start_date = '20000101'\n",
    "\n",
    "        attempt = 0\n",
    "        success = False\n",
    "        while attempt < retries and not success:\n",
    "            try:\n",
    "                # 拉取股票的日线数据\n",
    "                data = pro.daily(ts_code=code, start_date=start_date, end_date=end_date)\n",
    "\n",
    "                if data is not None and len(data) > 0:\n",
    "                    if insert_sql(data, 'stock_data'):\n",
    "                        log_status(code, 'success')\n",
    "                        new_count += 1\n",
    "                        success = True\n",
    "                    else:\n",
    "                        log_status(code, 'failure', '插入数据库失败')\n",
    "                        attempt += 1\n",
    "                else:\n",
    "                    log_status(code, 'failure', '无数据返回')\n",
    "                    skipped_count += 1\n",
    "                    success = True\n",
    "            except Exception as e:\n",
    "                log_status(code, 'failure', str(e))\n",
    "                attempt += 1\n",
    "\n",
    "    # 使用 ThreadPoolExecutor 并行处理所有股票\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:\n",
    "        futures = [executor.submit(process_stock, code) for code in stock_codes]\n",
    "\n",
    "        # 持续检查并更新进度\n",
    "        while True:\n",
    "            completed_futures = sum(1 for future in futures if future.done())\n",
    "            total_processed = skipped_count + new_count\n",
    "            print(f\"\\r拉取总进度：{total_processed}/{total_stocks}，已跳过 {skipped_count}/{total_stocks}\", end='', flush=True)\n",
    "            \n",
    "            # 如果所有任务完成，则退出\n",
    "            if completed_futures == total_stocks:\n",
    "                break\n",
    "\n",
    "    # 确保最后打印完整的输出\n",
    "    print(\"\\n所有股票数据处理完成。\")\n",
    "\n",
    "# 设置日期范围\n",
    "start_date = '20000101'\n",
    "end_date = '20141231'\n",
    "\n",
    "# 开始并行拉取并插入数据\n",
    "fetch_and_insert_data_parallel(stock_codes, start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400a2f67-126b-4a25-a4a8-2c84bdbe19cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "# 输出多周期 k 线\n",
    "# 输入的日线数据CSV文件路径\n",
    "input_csv = '300467_data.csv'\n",
    "\n",
    "# 读取日线数据\n",
    "df = pd.read_csv(input_csv)\n",
    "\n",
    "# 确保日期列是datetime类型，并按日期排序\n",
    "df['trade_date'] = pd.to_datetime(df['trade_date'], format='%Y%m%d')  # 日期格式是'YYYYMMDD'\n",
    "df = df.sort_values(by='trade_date')\n",
    "\n",
    "# 获取股票代码（假设所有数据来自同一股票）\n",
    "ts_code = df['ts_code'].iloc[0]  # 取第一个数据的股票代码\n",
    "\n",
    "# 创建以股票代码为名字的文件夹，如果文件夹不存在则创建\n",
    "output_dir = f\"./{ts_code}\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# 定义聚合函数\n",
    "def resample_data(df, freq):\n",
    "    \"\"\"\n",
    "    根据不同频率（'W', 'M', 'Q', 'Y'）对日线数据进行重采样\n",
    "    \"\"\"\n",
    "    df_resampled = df.resample(freq, on='trade_date').agg({\n",
    "        'ts_code': 'first',        # 股票代码（取第一个）\n",
    "        'open': 'first',           # 开盘价（周期内的第一个）\n",
    "        'high': 'max',             # 最高价（周期内的最大值）\n",
    "        'low': 'min',              # 最低价（周期内的最小值）\n",
    "        'close': 'last',           # 收盘价（周期内的最后一个）\n",
    "        'pre_close': 'last',       # 前收盘价（周期内最后一个的前收盘价）\n",
    "        'change': 'last',          # 涨跌额（最后一根K线的涨跌额）\n",
    "        'pct_chg': 'last',         # 涨跌幅（最后一根K线的涨跌幅）\n",
    "        'vol': 'sum',              # 成交量（周期内成交量的总和）\n",
    "        'amount': 'sum'            # 成交额（周期内成交额的总和）\n",
    "    }).dropna()  # 删除缺失值\n",
    "\n",
    "    # 重置索引，便于后续操作\n",
    "    return df_resampled.reset_index()\n",
    "\n",
    "# 生成周线数据\n",
    "df_weekly = resample_data(df, 'W-MON')\n",
    "df_weekly.to_csv(f\"{output_dir}/weekly_data.csv\", index=False)\n",
    "\n",
    "# 生成月线数据\n",
    "df_monthly = resample_data(df, 'M')\n",
    "df_monthly.to_csv(f\"{output_dir}/monthly_data.csv\", index=False)\n",
    "\n",
    "# 生成季线数据\n",
    "df_quarterly = resample_data(df, 'Q')\n",
    "df_quarterly.to_csv(f\"{output_dir}/quarterly_data.csv\", index=False)\n",
    "\n",
    "# 生成年线数据\n",
    "df_yearly = resample_data(df, 'Y')\n",
    "df_yearly.to_csv(f\"{output_dir}/yearly_data.csv\", index=False)\n",
    "\n",
    "print(f\"周线数据已保存到: {output_dir}/weekly_data.csv\")\n",
    "print(f\"月线数据已保存到: {output_dir}/monthly_data.csv\")\n",
    "print(f\"季线数据已保存到: {output_dir}/quarterly_data.csv\")\n",
    "print(f\"年线数据已保存到: {output_dir}/yearly_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b59a620d-d32b-408b-9103-fd5752853b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9w/fy4wsg5j6dx5tqtwh1ltqmrh0000gn/T/ipykernel_62182/738918401.py:31: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    }
   ],
   "source": [
    "import pymysql\n",
    "import pandas as pd\n",
    "\n",
    "'''\n",
    "从数据库查询并导出多周期 k 线\n",
    "'''\n",
    "\n",
    "conn = pymysql.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    database=\"stocks\"\n",
    ")\n",
    "\n",
    "# 定义 SQL 查询\n",
    "query = \"\"\"\n",
    "SELECT\n",
    "    ts_code,\n",
    "    YEAR(trade_date) AS year,\n",
    "    MIN(open) AS open,\n",
    "    MAX(high) AS high,\n",
    "    MIN(low) AS low,\n",
    "    MAX(close) AS close,\n",
    "    SUM(vol) AS volume,\n",
    "    SUM(amount) AS amount\n",
    "FROM\n",
    "    merged_stock_data\n",
    "GROUP BY\n",
    "    ts_code, YEAR(trade_date)\n",
    "ORDER BY\n",
    "    ts_code, year;\n",
    "\"\"\"\n",
    "\n",
    "# 使用 Pandas 执行查询并将结果加载为 DataFrame\n",
    "df = pd.read_sql(query, conn)\n",
    "\n",
    "# 将查询结果保存为 CSV 文件\n",
    "df.to_csv('./stock_data.csv', index=False)\n",
    "\n",
    "# 关闭连接\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e60c2fd-3f7b-4be2-95aa-09e33f9943b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [ts_code, trade_date, open, high, low, close, pre_close, change, pct_chg, vol, amount]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [ts_code, trade_date, open, high, low, close, pre_close, change, pct_chg, vol, amount]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 加载数据\n",
    "data_file1 = '/Users/sean/Jupyter_Projects/StockDataPrep/data/1merged_stocks_data_20241204.csv'\n",
    "data_file2 = '/Users/sean/Jupyter_Projects/StockDataPrep/data/merged_stocks_data_qfq_20241204.csv'\n",
    "df1 = pd.read_csv(data_file1)\n",
    "df2 = pd.read_csv(data_file2)\n",
    "\n",
    "# 筛选出 ts_code 为 603689.SH 和 603790.SH 的数据\n",
    "filtered_data1 = df1[df1['ts_code'].isin(['603206.SH', '600525.SH'])]\n",
    "filtered_data2 = df1[df1['ts_code'].isin(['603206.SH', '600525.SH'])]\n",
    "\n",
    "# 查看筛选后的数据\n",
    "print(filtered_data1)\n",
    "print(filtered_data2)\n",
    "\n",
    "# 如果只需要查看这两只股票的部分数据（如前5行），可以使用 .head()\n",
    "print(filtered_data1.head())\n",
    "print(filtered_data1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab5c3720-6d28-4b24-a81c-33ac37e178a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10230025, 11)\n"
     ]
    }
   ],
   "source": [
    "# 查看筛选后的数据的行数和列数\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b4f5b5a-b233-4c79-a958-6f153411ab82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "唯一的股票数量: 4324\n"
     ]
    }
   ],
   "source": [
    "# 获取筛选后的数据中唯一的股票代码数量\n",
    "unique_stock_count = df['ts_code'].nunique()\n",
    "print(f'唯一的股票数量: {unique_stock_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebebdf23-177f-4a9d-a258-632f5d96eb83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ts_code  trade_date   open   high    low  close  pre_close  change  \\\n",
      "0  301237.SZ    20241204  25.36  25.36  24.50  24.70      25.30   -0.60   \n",
      "1  301237.SZ    20241203  25.47  25.47  25.07  25.30      25.17    0.13   \n",
      "2  301237.SZ    20241202  24.72  25.25  24.72  25.17      24.72    0.45   \n",
      "3  301237.SZ    20241129  24.27  25.00  24.27  24.72      24.55    0.17   \n",
      "4  301237.SZ    20241128  24.25  24.99  23.94  24.55      24.24    0.31   \n",
      "\n",
      "   pct_chg     vol     amount  \n",
      "0  -2.3715  5732.0  14304.951  \n",
      "1   0.5165  5823.1  14703.321  \n",
      "2   1.8204  8114.0  20323.521  \n",
      "3   0.6925  5180.0  12772.430  \n",
      "4   1.2789  6935.0  17077.050  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 加载数据\n",
    "#data_file = '/Users/sean/Jupyter_Projects/StockDataPrep/data/基础数据_预处理20241128.csv'\n",
    "#data_file = '/Users/sean/Jupyter_Projects/StockDataPrep/data/merged_stocks_data_20241128.csv'\n",
    "data_file2 = '/Users/sean/Jupyter_Projects/StockDataPrep/data/merged_stocks_data_qfq_20241204.csv'  # 前复权\n",
    "\n",
    "dfs = pd.read_csv(data_file2)\n",
    "\n",
    "\n",
    "# 如果只需要查看这两只股票的部分数据（如前5行），可以使用 .head()\n",
    "print(dfs.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ab36694-4487-4a4e-8095-6621a314395e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "唯一的股票数量: 4375\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 加载数据\n",
    "#data_file = '/Users/sean/Jupyter_Projects/StockDataPrep/data/基础数据_预处理20241128.csv'\n",
    "data_file = '/Users/sean/Jupyter_Projects/StockDataPrep/data/merged_stocks_data_20241128.csv'\n",
    "dfs = pd.read_csv(data_file)\n",
    "\n",
    "# 获取筛选后的数据中唯一的股票代码数量\n",
    "sunique_stock_count = dfs['ts_code'].nunique()\n",
    "print(f'唯一的股票数量: {sunique_stock_count}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6db58be5-d850-4f62-aeda-3998885024e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "import pandas as pd\n",
    "\n",
    "def update_stock_data_to_mysql(data, db_config):\n",
    "    \"\"\"\n",
    "    将股票数据更新到 MySQL 数据库。\n",
    "\n",
    "    :param data: 包含股票数据的 DataFrame\n",
    "    :param db_config: 数据库配置字典，包含 'host', 'user', 'password', 'database'\n",
    "    \"\"\"\n",
    "    # 连接数据库\n",
    "    connection = pymysql.connect(\n",
    "        host=db_config['host'],\n",
    "        user=db_config['user'],\n",
    "        database=db_config['database']\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        # 创建数据库操作游标\n",
    "        cursor = connection.cursor()\n",
    "\n",
    "        # 获取数据库中已存在的最大日期（检查是否有重复数据）\n",
    "        cursor.execute(\"SELECT MAX(trade_date) FROM merged_stock_data\")  # 根据实际表名修改\n",
    "        max_date = cursor.fetchone()[0]  # 取得最大日期\n",
    "\n",
    "        if max_date:\n",
    "            # 过滤出新数据\n",
    "            new_data = data[data['trade_date'] > max_date]\n",
    "        else:\n",
    "            # 如果数据库为空，插入所有数据\n",
    "            new_data = data\n",
    "\n",
    "        if not new_data.empty:\n",
    "            # 将数据插入数据库\n",
    "            for _, row in new_data.iterrows():\n",
    "                # 插入语句，字段名加反引号以避免与保留字冲突\n",
    "                sql = \"\"\"\n",
    "                    INSERT INTO stock_data (`ts_code`, `trade_date`, `open`, `high`, `low`, `close`, `pre_close`, `change`, `pct_chg`, `vol`, `amount`)\n",
    "                    VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "                    ON DUPLICATE KEY UPDATE\n",
    "                        `open` = VALUES(`open`),\n",
    "                        `high` = VALUES(`high`),\n",
    "                        `low` = VALUES(`low`),\n",
    "                        `close` = VALUES(`close`),\n",
    "                        `pre_close` = VALUES(`pre_close`),\n",
    "                        `change` = VALUES(`change`),\n",
    "                        `pct_chg` = VALUES(`pct_chg`),\n",
    "                        `vol` = VALUES(`vol`),\n",
    "                        `amount` = VALUES(`amount`)\n",
    "                \"\"\"\n",
    "                cursor.execute(sql, tuple(row))\n",
    "\n",
    "            # 提交事务\n",
    "            connection.commit()\n",
    "            print(f\"成功插入 {len(new_data)} 条新数据\")\n",
    "        else:\n",
    "            print(\"没有新数据需要插入。\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"数据库更新失败：{e}\")\n",
    "    finally:\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "\n",
    "\n",
    "# 假设已经拉取的股票数据存储在 DataFrame `stock_data` 中\n",
    "# update_stock_data_to_mysql(stock_data, db_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab638f1d-579b-4d0a-9493-ae6a285a423c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在读取文件: /Users/sean/Jupyter_Projects/StockDataPrep/data/merged_stocks_data_20241128.csv\n",
      "数据库更新失败：(1146, \"Table 'stocks.stock_data' doesn't exist\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "# 数据库配置（在这里定义一次）\n",
    "db_config = {\n",
    "    'host': 'localhost',\n",
    "    'user': 'root',\n",
    "    'database': 'stocks'\n",
    "}\n",
    "\n",
    "def get_latest_csv_file(directory):\n",
    "    \"\"\"\n",
    "    获取目录中最新的 CSV 文件。\n",
    "    \n",
    "    :param directory: 存放 CSV 文件的目录\n",
    "    :return: 最新的 CSV 文件路径\n",
    "    \"\"\"\n",
    "    # 搜索匹配的 CSV 文件\n",
    "    file_pattern = os.path.join(directory, \"merged_stocks_data_*.csv\")\n",
    "    files = glob.glob(file_pattern)\n",
    "    \n",
    "    if not files:\n",
    "        raise FileNotFoundError(\"没有找到符合条件的文件\")\n",
    "    \n",
    "    # 按文件名后缀的日期排序，取最新的文件\n",
    "    latest_file = max(files, key=lambda x: os.path.basename(x).split('_')[-1].replace('.csv', ''))\n",
    "    return latest_file\n",
    "\n",
    "def update_stock_data_from_csv(csv_file_path, db_config):\n",
    "    \"\"\"\n",
    "    读取 CSV 文件并更新数据库。\n",
    "    \n",
    "    :param csv_file_path: CSV 文件路径\n",
    "    :param db_config: 数据库配置\n",
    "    \"\"\"\n",
    "    # 读取 CSV 文件\n",
    "    stock_data = pd.read_csv(csv_file_path)\n",
    "    \n",
    "    # 调用数据库更新函数\n",
    "    update_stock_data_to_mysql(stock_data, db_config)\n",
    "\n",
    "# 获取最新的 CSV 文件路径\n",
    "directory = '/Users/sean/Jupyter_Projects/StockDataPrep/data'  \n",
    "latest_csv_file = get_latest_csv_file(directory)\n",
    "\n",
    "print(f\"正在读取文件: {latest_csv_file}\")\n",
    "\n",
    "update_stock_data_from_csv(latest_csv_file, db_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c01abcaf-3752-48c4-867b-3b24b8f6c1c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "未复权最高价数据：\n",
      "ts_code       300467.SZ\n",
      "trade_date     20190312\n",
      "close             32.96\n",
      "Name: 5575304, dtype: object\n",
      "\n",
      "前复权最高价数据：\n",
      "ts_code       300467.SZ\n",
      "trade_date     20190312\n",
      "close             32.96\n",
      "Name: 5613905, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 文件路径\n",
    "data_file1 = '/Users/sean/Jupyter_Projects/StockDataPrep/data/1merged_stocks_data_20241204.csv'  # 未复权\n",
    "data_file2 = '/Users/sean/Jupyter_Projects/StockDataPrep/data/merged_stocks_data_qfq_20241204.csv'  # 前复权\n",
    "\n",
    "# 加载数据\n",
    "df1 = pd.read_csv(data_file1)\n",
    "df2 = pd.read_csv(data_file2)\n",
    "\n",
    "# 选择股票代码和年份\n",
    "selected_stocks = ['300467.SZ']  # 替换为实际股票代码\n",
    "year = '2019'  # 查询的年份\n",
    "\n",
    "# 筛选数据：未复权\n",
    "filtered_data1 = df1[(df1['ts_code'].isin(selected_stocks)) & (df1['trade_date'].astype(str).str[:4] == year)]\n",
    "max_close_raw = filtered_data1.loc[filtered_data1['close'].idxmax()]  # 获取未复权的最高价记录\n",
    "\n",
    "# 筛选数据：前复权\n",
    "filtered_data2 = df2[(df2['ts_code'].isin(selected_stocks)) & (df2['trade_date'].astype(str).str[:4] == year)]\n",
    "max_close_qfq = filtered_data2.loc[filtered_data2['close'].idxmax()]  # 获取前复权的最高价记录\n",
    "\n",
    "# 输出结果\n",
    "print(\"未复权最高价数据：\")\n",
    "print(max_close_raw[['ts_code', 'trade_date', 'close']])\n",
    "\n",
    "print(\"\\n前复权最高价数据：\")\n",
    "print(max_close_qfq[['ts_code', 'trade_date', 'close']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9da71be-f4e2-4dcb-bae5-cfa9e9dd0417",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
